{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3b04d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n",
      "True\n",
      "1\n",
      "cuda\n",
      "tensor([-0.9516], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "x= torch.randn(1).cuda()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b8f937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = './data'\n",
    "#transform to tensor and normalize\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "#download trainset\n",
    "cifar10 = torchvision.datasets.CIFAR10(data_path,train=True,download =True,transform = transform)\n",
    "\n",
    "#setup trainloader\n",
    "cifar10_loader = torch.utils.data.DataLoader(cifar10, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "#download testset\n",
    "cifar10_val = torchvision.datasets.CIFAR10(data_path,train=False,download =True,transform = transform)\n",
    "\n",
    "#setup testloader\n",
    "cifar10_val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=batch_size,shuffle=False)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d21f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model P1A\n",
    "\n",
    " #used 3072 since one pic is 32 x 32 res, and 3 pixel coloration inputs per pixel, 32 x 32 x 3 = 3072\n",
    "model = nn.Sequential(\\\n",
    "                 nn.Linear(3072,512),\\\n",
    "                 nn.Tanh(),\\\n",
    "                 nn.Linear(512,10),\\\n",
    "                 nn.LogSoftmax(dim=1))\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "#LOSS\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "#OPTIMIZER\n",
    "#optimizer = optim.Adam(model.parameters(),lr=0.01,weight_decay=0.003) \n",
    "optimizer = optim.SGD(model.parameters(),lr=0.000560114, momentum=0.9) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf35b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.exp(x).sum() # for 0.09, e^1/(e^1 + e^2 + e^3) where top is 1\n",
    "#x = torch.tensor([1.0,2.0,3.0])\n",
    "\n",
    "#softmax(x)\n",
    "#imgs, labels = cifar10_loader\n",
    "#print(imgs.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518c91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(n_epoch):\n",
    "    t0 = time.time()\n",
    "    #torch.cuda.empty_cache()\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "       \n",
    "        \n",
    "        for imgs, labels in cifar10_loader:\n",
    "            imgs,labels = imgs.to(device),labels.to(device)\n",
    "            batch_size = imgs.shape[0] #takes image data, puts into 0 x data tensor\n",
    "            outputs = model(imgs.view(batch_size, -1)) #unsqueeze(0) adds dimensionality at dimension 0, (0,1)--> (0,1,2) where 1 is the new dimension\n",
    "            loss = criterion(outputs,labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #torch.cuda.empty_cache()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\" Epoch: %d, Loss: %F\" % (epoch, float(loss)))\n",
    "    print(f'training time = {time.time()-t0}')\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in cifar10_val_loader:\n",
    "            imgs,labels = imgs.to(device),labels.to(device)\n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs.view(batch_size,-1))\n",
    "            _,predicted = torch.max(outputs,dim=1)\n",
    "            total += labels.shape[0] #create \n",
    "            correct += int((predicted == labels).sum()) # if predicted is the answer, add it to sum\n",
    "    print(correct)\n",
    "    print(total)\n",
    "    print(\"Accuracy: %f\", correct / total)\n",
    "    \n",
    "#training(3)\n",
    "#note, this is really bad, accuracy = 38.47%,possibly also wasn't learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "054ee9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 2a\n",
    "model = nn.Sequential(\\\n",
    "                 nn.Linear(3072,1024),\\\n",
    "                 nn.LeakyReLU(),\\\n",
    "                 nn.Linear(1024,512),\\\n",
    "                 nn.LeakyReLU(),\\\n",
    "                 nn.Linear(512,128),\\\n",
    "                 nn.LeakyReLU(),\\\n",
    "                 nn.Linear(128,10)\\\n",
    "                     )\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "#training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b91ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_cnn(n_epoch):\n",
    "    t0 = time.time()\n",
    "    #torch.cuda.empty_cache()\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "       \n",
    "        \n",
    "        for imgs, labels in cifar10_loader:\n",
    "            imgs,labels = imgs.to(device),labels.to(device)\n",
    "            batch_size = imgs.shape[0] #takes image data, puts into 0 x data tensor\n",
    "            outputs = model(imgs) #unsqueeze(0) adds dimensionality at dimension 0, (0,1)--> (0,1,2) where 1 is the new dimension\n",
    "            loss = criterion(outputs,labels)                 # [[1,2,3]] --> [[[1],[2],[3]]]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #torch.cuda.empty_cache()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\" Epoch: %d, Loss: %F\" % (epoch, float(loss)))\n",
    "    print(f'training time = {time.time()-t0}')\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in cifar10_val_loader:\n",
    "            imgs,labels = imgs.to(device),labels.to(device)\n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs)\n",
    "            _,predicted = torch.max(outputs,dim=1)\n",
    "            total += labels.shape[0] #create \n",
    "            correct += int((predicted == labels).sum()) # if predicted is the answer, add it to sum\n",
    "    print(correct)\n",
    "    print(total)\n",
    "    print(\"Accuracy: %f\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f16f21c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0, Loss: 2.395412\n",
      " Epoch: 1, Loss: 2.289831\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m model()\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtraining_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mtraining_cnn\u001b[1;34m(n_epoch)\u001b[0m\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#torch.cuda.empty_cache()\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Epoch: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m%F\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, \u001b[38;5;28mfloat\u001b[39m(loss)))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aiclass\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aiclass\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Problem 1b\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6, 5) #3,16,kernel_size=3,padding=1\n",
    "        self.conv2 = nn.Conv2d(6,16,5) #16,8,kernel_size=3,padding=1\n",
    "        self.fc1 = nn.Linear(16*5*5,128)\n",
    "        self.fc2 = nn.Linear(128,16)\n",
    "        self.fc3 = nn.Linear(16,10)\n",
    "    def forward(self,x):\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        out = F.max_pool2d(F.relu(self.conv2(out)),2)\n",
    "        out = out.view(-1, 16*5*5)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "model = model()\n",
    "model = model.to(device)\n",
    "\n",
    "training_cnn(300)# YOU BUFFOON, YOU ONLY FOUND THE BEST STRUCTURE FOR 10 PICTURES, NOT THE 50,000 SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29be0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiclass",
   "language": "python",
   "name": "aiclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
